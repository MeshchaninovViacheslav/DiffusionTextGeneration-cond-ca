{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7d18a-6e95-44a8-a7bb-33163c7f2b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ce2fb3-4ffe-4c76-8444-26690fb9b38a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "from transformers import AutoTokenizer, T5Model, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28b1de-b840-4a13-a3fe-b9a420a06fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38c27dc-4d91-402d-a8a9-157e9f0a43e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"i went well into an interview yesterday. i did not know how to do my homework. i had to wait a long day for the interview to do well. even when i arrived the next morning, the interview had failed. i was disappointed to learn that i could not finish my paper.\",\n",
    "    \"jack wanted to cook a cake for his wife. he put the cupboard in the cupboarder. he put a big cupboard in the oven. jack was disappointed when his wife's family was done. the ovenboard turned out looking perfectly perfect!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e46b20-71a8-4db1-80ef-2f51c2b34ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8fa8087-34b8-4c4f-9ee4-aba0a6832b24",
   "metadata": {},
   "source": [
    "# T5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43b6e9d-9ef4-4cda-83a5-256e9e3780aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c7cfe1-8b23-4213-8182-0bb73b456226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3, 23, 877, 168, 139, 46, 2772, 4981, 5, 3, 23, 410, 59, 214, 149, 12, 103, 82, 11920, 5, 3, 23, 141, 12, 1749, 3, 9, 307, 239, 21, 8, 2772, 12, 103, 168, 5, 237, 116, 3, 23, 4363, 8, 416, 1379, 6, 8, 2772, 141, 4567, 5, 3, 23, 47, 10978, 12, 669, 24, 3, 23, 228, 59, 1992, 82, 1040, 5, 1], [3, 9325, 1114, 12, 3989, 3, 9, 4340, 21, 112, 2512, 5, 3, 88, 474, 8, 19904, 16, 8, 19904, 49, 5, 3, 88, 474, 3, 9, 600, 19904, 16, 8, 4836, 5, 3, 9325, 47, 10978, 116, 112, 2512, 31, 7, 384, 47, 612, 5, 8, 4836, 1976, 2120, 91, 479, 3923, 626, 55, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "710aef0e-5d4b-47d6-b264-960c5633e581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.vocab[t5_tokenizer.eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c10ae3a-52fa-49fb-933a-a0f0f6d2d455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.vocab[t5_tokenizer._pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "685f2fa4-ee88-4caf-8dff-26c31c4f8841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.vocab[t5_tokenizer._unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c88a172-f7e4-47e9-bb75-3771f98938da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 23\n",
      ". 5\n",
      "‚ñÅ 3\n"
     ]
    }
   ],
   "source": [
    "for k, v in t5_tokenizer.vocab.items():\n",
    "    if v in [3, 23, 5]:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236f8037-f1cb-49a6-bdbc-1db23f6c58cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1]], 'attention_mask': [[1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ee7789-45b2-4b33-9b84-04fa1902bf19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3, 23, 1]], 'attention_mask': [[1, 1, 1]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer([\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6007771b-d687-4c40-be0a-569cd8479234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[27, 1]], 'attention_mask': [[1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer([\"I\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97450450-0808-40e1-a6c3-4646eb003c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i</s>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.batch_decode([[3, 23, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "731aae83-7c13-4b6b-933a-12ba5ea11c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.batch_decode([[23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31929ed8-2411-4215-9914-e381e48eeca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3, 23, 410, 59, 214, 149, 12, 103, 82, 11920, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer([\"i did not know how to do my homework.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead99a72-6bb0-4504-822c-8aa3a2451fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i did not know how to do my homework.</s>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.batch_decode([[3, 23, 410, 59, 214, 149, 12, 103, 82, 11920, 5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee6f528-8d05-418f-9458-c3412405c6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i  did not know how to do my homework.</s>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.batch_decode([[3, 23, 3, 410, 59, 214, 149, 12, 103, 82, 11920, 5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7360bcc-6bcd-4fd6-ae61-bb9d7cd7e755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "453a0177-351b-46c5-b530-5500a493ae59",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674c2e0b-0706-4a54-a852-6374434f85e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.encoder_t5 import T5EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40cecf9-5e7b-42ee-8467-8bd6b01456a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bec0ab0-300a-4969-9a6f-952fd767b7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "t5_encoder = T5EncoderModel.from_pretrained(\n",
    "    \"t5-base\",\n",
    "    enc_normalizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1df50d7-e71f-4acc-9636-88ca47e20ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = encoder.shared.weight.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80c3d664-1f45-4148-8124-dae0d608ceb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ = t5_tokenizer(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=80,\n",
    "    return_tensors='pt',\n",
    "    return_special_tokens_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff5df3c2-bfe0-48ad-9eee-2151ff6fec2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encodings = t5_encoder(input_ids=input_[\"input_ids\"], attention_mask=input_[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "533c2585-565d-42de-918f-4751f968049b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token = 1 - input_['special_tokens_mask']\n",
    "mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71ec9b0c-8a77-42f7-bd8b-676b53bd78bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm(z, mask):\n",
    "    norm = torch.sum(torch.norm(z, dim=2) * mask) / torch.sum(mask)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "941a5a25-85f0-4919-9f10-dc97a1ea69ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9983, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token's norm\n",
    "norm(encodings, mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a584a5b1-5921-4a5a-974a-589e31196b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3005, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad's norm\n",
    "norm(encodings, 1 - mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e511c5-e9b9-44c5-b7c5-225d47a70ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a677d29d-452b-49d4-af2d-5b1c9c748eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = t5_encoder.shared.weight.data.cpu()\n",
    "eos_emb = embeddings[t5_tokenizer.eos_token_id].cuda()\n",
    "pad_emb = embeddings[t5_tokenizer.pad_token_id].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b079d3fd-8cc7-488c-bc3c-78f6626dda91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_emb / torch.norm(eos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "349a5d77-ad37-433b-88c9-65cfcc6d5017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(664.7014, device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(pad_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c421dea9-9804-400f-9436-3188b676a228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_['special_tokens_mask'] * input_['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bfc3a-0e4f-4b58-b8de-970c3705a8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65475513-5bbd-4a47-8064-cf404553a639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936d2f5-4038-4976-88d1-e7bd4a97b0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-env]",
   "language": "python",
   "name": "conda-env-anaconda3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
